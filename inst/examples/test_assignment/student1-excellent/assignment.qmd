---
title: "Data Analysis Assignment"
author: "Alex Chen"
date: "2024-03-15"
format: html
---

# Introduction

This assignment explores fundamental concepts in R programming and statistical analysis. I will demonstrate my understanding of R syntax, data manipulation, and visualization techniques through a series of practical exercises.

## Question 1: Understanding R

**Explain what R is and describe its main uses in data science:**

R is a powerful open-source programming language and software environment specifically designed for statistical computing and graphics. Originally developed by Ross Ihaka and Robert Gentleman at the University of Auckland in the 1990s, R has become one of the most widely used tools in data science, statistics, and research.

Key characteristics and uses of R include:

- **Statistical Analysis**: R provides comprehensive statistical functions including descriptive statistics, hypothesis testing, regression analysis, time series analysis, and advanced modeling techniques
- **Data Manipulation**: Excellent tools for cleaning, transforming, and reshaping data through packages like dplyr and tidyr
- **Visualization**: Outstanding graphics capabilities through base R plotting and advanced packages like ggplot2, enabling creation of publication-quality visualizations
- **Reproducible Research**: Integration with R Markdown allows for creating dynamic reports that combine code, results, and narrative
- **Package Ecosystem**: Over 18,000 packages available on CRAN covering virtually every statistical method and domain-specific application
- **Community**: Large, active community providing support, packages, and educational resources

## Question 2: Basic Programming

**Write code to calculate descriptive statistics for a numeric vector:**

```{r descriptive-stats}
# Create a sample dataset
data_vector = c(12, 15, 18, 22, 25, 28, 31, 35, 42, 48, 51, 55, 62, 68, 75)

# Calculate comprehensive descriptive statistics
cat("Descriptive Statistics for the Dataset:\n")
cat("=====================================\n")
cat("Sample size:", length(data_vector), "\n")
cat("Mean:", round(mean(data_vector), 2), "\n")
cat("Median:", median(data_vector), "\n")
cat("Standard deviation:", round(sd(data_vector), 2), "\n")
cat("Variance:", round(var(data_vector), 2), "\n")
cat("Range:", range(data_vector), "\n")
cat("Interquartile range:", round(IQR(data_vector), 2), "\n")

# Calculate quartiles
quartiles = quantile(data_vector, probs = c(0.25, 0.5, 0.75))
cat("First quartile (Q1):", quartiles[1], "\n")
cat("Second quartile (Q2/Median):", quartiles[2], "\n")
cat("Third quartile (Q3):", quartiles[3], "\n")

# Additional statistics
cat("Minimum value:", min(data_vector), "\n")
cat("Maximum value:", max(data_vector), "\n")
cat("Sum:", sum(data_vector), "\n")
```

## Question 3: Data Visualization

**Create an informative visualization demonstrating advanced plotting techniques:**

```{r advanced-visualization}
# Load required libraries
library(ggplot2)
library(dplyr)

# Create a more complex dataset for demonstration
set.seed(42)  # For reproducibility
n = 100
data_df = data.frame(
  x = seq(1, 10, length.out = n),
  group = rep(c("A", "B", "C"), length.out = n)
) %>%
  mutate(
    y = case_when(
      group == "A" ~ 2 * x + rnorm(n, 0, 1),
      group == "B" ~ x^1.5 + rnorm(n, 0, 1.5),
      group == "C" ~ 15 - 0.5 * x^1.2 + rnorm(n, 0, 1)
    ),
    y = pmax(y, 0)  # Ensure no negative values
  )

# Create a sophisticated multi-panel visualization
p1 = ggplot(data_df, aes(x = x, y = y, color = group)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "loess", se = TRUE, alpha = 0.3) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  labs(
    title = "Relationship between X and Y by Group",
    subtitle = "With LOESS smoothing and confidence intervals",
    x = "X Variable",
    y = "Y Variable",
    color = "Group"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    legend.position = "bottom"
  )

print(p1)

# Additional summary statistics by group
summary_stats = data_df %>%
  group_by(group) %>%
  summarise(
    count = n(),
    mean_x = round(mean(x), 2),
    mean_y = round(mean(y), 2),
    sd_y = round(sd(y), 2),
    .groups = 'drop'
  )

print(summary_stats)
```

## Question 4: Advanced Analysis

**Perform a correlation analysis and interpretation:**

```{r correlation-analysis}
# Calculate correlation matrix for numeric variables
correlation_matrix = cor(data_df[c("x", "y")])
print("Overall Correlation Matrix:")
print(round(correlation_matrix, 3))

# Correlation by group
cat("\nCorrelation coefficients by group:\n")
for(grp in unique(data_df$group)) {
  subset_data = data_df[data_df$group == grp, ]
  correlation = cor(subset_data$x, subset_data$y)
  cat("Group", grp, ":", round(correlation, 3), "\n")
}

# Statistical significance test
cor_test = cor.test(data_df$x, data_df$y)
cat("\nCorrelation test results:\n")
cat("Correlation coefficient:", round(cor_test$estimate, 3), "\n")
cat("P-value:", format(cor_test$p.value, scientific = TRUE), "\n")
cat("95% Confidence interval:", round(cor_test$conf.int, 3), "\n")
```

# Conclusion

This assignment has successfully demonstrated several key concepts in R programming and data analysis:

1. **Theoretical Understanding**: I explained R's role in data science and its comprehensive ecosystem
2. **Statistical Computing**: I calculated and interpreted descriptive statistics for understanding data distribution
3. **Data Visualization**: I created professional-quality plots using ggplot2 with multiple aesthetic mappings and statistical overlays
4. **Statistical Analysis**: I performed correlation analysis with proper statistical testing and interpretation

The code examples showcase best practices including:
- Proper documentation and commenting
- Use of appropriate statistical methods
- Clear and informative visualizations
- Reproducible analysis with set.seed()
- Professional formatting and interpretation of results

These skills form the foundation for more advanced data science applications and statistical modeling in R.